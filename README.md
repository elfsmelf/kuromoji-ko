# kuromoji-ko

**Pure JavaScript Korean Morphological Analyzer**

A port of [kuromoji.js](https://github.com/takuyaa/kuromoji.js) adapted for Korean language processing using [mecab-ko-dic](https://bitbucket.org/eunjeon/mecab-ko-dic).

## Features

- ğŸš€ Pure JavaScript - runs in Node.js, browsers, and serverless (Vercel, Cloudflare Workers)
- ğŸ“¦ No native dependencies - no compilation required
- ğŸ‡°ğŸ‡· Korean-optimized - uses mecab-ko-dic with Sejong tagset
- âš¡ Viterbi algorithm - accurate morphological analysis
- ğŸ”§ Simple API - tokenize Korean text in a few lines

## Installation

```bash
npm install kuromoji-ko
```

## Quick Start

### napi-mecab Compatible API (Recommended)

```javascript
import { MeCab } from 'kuromoji-ko';

const mecab = await MeCab.create({ engine: 'ko', dictPath: './dict' });
const tokens = mecab.parse('ì•ˆë…•í•˜ì„¸ìš”');

for (const token of tokens) {
  console.log(token.surface, token.pos, token.lemma);
}
// ì•ˆë…• ['NNG'] ì•ˆë…•
// í•˜ ['XSV'] í•˜ë‹¤
// ì„¸ìš” ['EF'] ì„¸ìš”
```

### Classic API

```javascript
import kuromoji from 'kuromoji-ko';

const tokenizer = await kuromoji.builder({
  dicPath: './dict'
}).build();

const tokens = tokenizer.tokenize('ì•ˆë…•í•˜ì„¸ìš”');

for (const token of tokens) {
  console.log(token.surface_form, token.pos, token.posDescription);
}
// ì•ˆë…• NNG ì¼ë°˜ ëª…ì‚¬
// í•˜ XSV ë™ì‚¬ íŒŒìƒ ì ‘ë¯¸ì‚¬
// ì„¸ìš” EF ì¢…ê²° ì–´ë¯¸
```

## Building the Dictionary

Before using kuromoji-ko, you need to build the dictionary files from mecab-ko-dic:

```bash
# Download mecab-ko-dic
git clone https://bitbucket.org/eunjeon/mecab-ko-dic.git

# Build dictionary
npm run build:dict -- ./mecab-ko-dic ./dict
```

This creates binary dictionary files in the `./dict` directory.

## API

### MeCab API (napi-mecab compatible)

#### `MeCab.create(options)`

Create a MeCab instance asynchronously.

```javascript
import { MeCab } from 'kuromoji-ko';

const mecab = await MeCab.create({
  engine: 'ko',      // Only 'ko' is supported
  dictPath: './dict' // Path to dictionary directory
});
```

#### `mecab.parse(text)`

Parse text into an array of Token objects.

```javascript
const tokens = mecab.parse('ì•„ë²„ì§€ê°€ë°©ì—ë“¤ì–´ê°€ì‹ ë‹¤');
tokens.forEach(t => console.log(t.surface, t.pos));
```

### Token Object (napi-mecab compatible)

| Property | Type | Description |
|----------|------|-------------|
| `surface` | `string` | How the token looks in the input text |
| `pos` | `string[]` | Parts of speech as array (split by "+") |
| `lemma` | `string` | Dictionary headword (adds "ë‹¤" for verbs) |
| `pronunciation` | `string \| null` | How the token is pronounced |
| `hasBatchim` | `boolean \| null` | Whether token has final consonant (ë°›ì¹¨) |
| `hasJongseong` | `boolean \| null` | Alias for hasBatchim |
| `semanticClass` | `string \| null` | Semantic word class or category |
| `type` | `string \| null` | Token type (Inflect/Compound/Preanalysis) |
| `expression` | `ExpressionToken[] \| null` | Breakdown of compound/inflected tokens |
| `features` | `string` | Raw features string (comma-separated) |
| `raw` | `string` | Raw MeCab output format (surface\tfeatures) |

### ExpressionToken Object

For compound or inflected words, `expression` returns an array of ExpressionToken:

| Property | Type | Description |
|----------|------|-------------|
| `morpheme` | `string` | The normalized token |
| `pos` | `string` | Part of speech |
| `lemma` | `string` | Dictionary form (adds "ë‹¤" for verbs) |
| `semanticClass` | `string \| null` | Semantic category |

---

### Classic API

#### `kuromoji.builder(options)`

Create a tokenizer builder.

```javascript
const builder = kuromoji.builder({
  dicPath: './dict',      // Path to dictionary directory
  loader: customLoader    // Optional custom file loader
});
```

### `builder.build()`

Build and return the tokenizer (async).

```javascript
const tokenizer = await builder.build();
```

### `tokenizer.tokenize(text)`

Tokenize Korean text into morphemes.

```javascript
const tokens = tokenizer.tokenize('í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„');
```

### `tokenizer.wakati(text)`

Get just the surface forms as an array.

```javascript
const words = tokenizer.wakati('í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„');
// ['í•œêµ­ì–´', 'í˜•íƒœì†Œ', 'ë¶„ì„']
```

### `tokenizer.wakatiString(text)`

Get space-separated surface forms.

```javascript
const str = tokenizer.wakatiString('í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„');
// 'í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„'
```

## KoreanToken Object (Classic API)

Each token from `tokenizer.tokenize()` has the following properties:

| Property | Description | Example |
|----------|-------------|---------|
| `surface_form` | Surface text | `'í•œêµ­ì–´'` |
| `word_position` | Position in text (1-indexed) | `1` |
| `word_id` | Dictionary word ID | `12345` |
| `word_type` | KNOWN or UNKNOWN | `'KNOWN'` |
| `pos` | POS tag (Sejong tagset) | `'NNG'` |
| `posDescription` | POS description | `'ì¼ë°˜ ëª…ì‚¬'` |
| `semantic_class` | Semantic category | `'*'` |
| `has_final_consonant` | Ends with ë°›ì¹¨? (T/F/*) | `'F'` |
| `reading` | Pronunciation | `'í•œêµ­ì–´'` |
| `type` | Inflect/Compound/Preanalysis | `'Compound'` |
| `first_pos` | First POS (compounds) | `'NNG'` |
| `last_pos` | Last POS (compounds) | `'NNG'` |
| `expression` | Decomposition | `'í•œêµ­/NNG/*+ì–´/NNG/*'` |

## Korean POS Tags (Sejong Tagset)

### ì²´ì–¸ (Substantives)
| Tag | Description |
|-----|-------------|
| NNG | ì¼ë°˜ ëª…ì‚¬ (General noun) |
| NNP | ê³ ìœ  ëª…ì‚¬ (Proper noun) |
| NNB | ì˜ì¡´ ëª…ì‚¬ (Dependent noun) |
| NR | ìˆ˜ì‚¬ (Numeral) |
| NP | ëŒ€ëª…ì‚¬ (Pronoun) |

### ìš©ì–¸ (Predicates)
| Tag | Description |
|-----|-------------|
| VV | ë™ì‚¬ (Verb) |
| VA | í˜•ìš©ì‚¬ (Adjective) |
| VX | ë³´ì¡° ìš©ì–¸ (Auxiliary) |
| VCP | ê¸ì • ì§€ì •ì‚¬ (Copula ì´ë‹¤) |
| VCN | ë¶€ì • ì§€ì •ì‚¬ (Negative ì•„ë‹ˆë‹¤) |

### ì¡°ì‚¬ (Particles)
| Tag | Description |
|-----|-------------|
| JKS | ì£¼ê²© ì¡°ì‚¬ (Subject) |
| JKO | ëª©ì ê²© ì¡°ì‚¬ (Object) |
| JKB | ë¶€ì‚¬ê²© ì¡°ì‚¬ (Adverbial) |
| JX | ë³´ì¡°ì‚¬ (Auxiliary particle) |

### ì–´ë¯¸ (Endings)
| Tag | Description |
|-----|-------------|
| EP | ì„ ì–´ë§ ì–´ë¯¸ (Pre-final) |
| EF | ì¢…ê²° ì–´ë¯¸ (Final) |
| EC | ì—°ê²° ì–´ë¯¸ (Connective) |
| ETN | ëª…ì‚¬í˜• ì „ì„± ì–´ë¯¸ (Nominalizing) |
| ETM | ê´€í˜•í˜• ì „ì„± ì–´ë¯¸ (Adnominalizing) |

### ê¸°íƒ€ (Others)
| Tag | Description |
|-----|-------------|
| SL | ì™¸êµ­ì–´ (Foreign) |
| SH | í•œì (Chinese characters) |
| SN | ìˆ«ì (Numbers) |
| SW | ê¸°íƒ€ ê¸°í˜¸ (Symbols) |

## Browser Usage

```html
<script type="module">
import kuromoji from 'https://cdn.jsdelivr.net/npm/kuromoji-ko/dist/index.mjs';

const tokenizer = await kuromoji.builder({
  dicPath: 'https://cdn.jsdelivr.net/npm/kuromoji-ko/dict/'
}).build();

console.log(tokenizer.tokenize('ì•ˆë…•í•˜ì„¸ìš”'));
</script>
```

## Serverless (Vercel) Usage

kuromoji-ko runs without native dependencies, making it perfect for serverless:

```javascript
// api/tokenize.js
import kuromoji from 'kuromoji-ko';

let tokenizerPromise = null;

function getTokenizer() {
  if (!tokenizerPromise) {
    tokenizerPromise = kuromoji.builder({
      dicPath: './dict'
    }).build();
  }
  return tokenizerPromise;
}

export default async function handler(req, res) {
  const tokenizer = await getTokenizer();
  const tokens = tokenizer.tokenize(req.body.text);
  res.json(tokens);
}
```

## How It Works

kuromoji-ko implements morphological analysis using:

1. **Double-Array TRIE** - Efficient dictionary lookup for surface forms
2. **Viterbi Algorithm** - Dynamic programming to find the optimal segmentation
3. **Connection Costs** - Bigram model for morpheme transitions
4. **Unknown Word Handling** - Character-type based POS estimation

## Credits

- [kuromoji.js](https://github.com/takuyaa/kuromoji.js) - Original Japanese implementation
- [mecab-ko-dic](https://bitbucket.org/eunjeon/mecab-ko-dic) - Korean dictionary
- [MeCab](https://taku910.github.io/mecab/) - Original C++ morphological analyzer

## License

Apache-2.0

Dictionary files (mecab-ko-dic) are also Apache-2.0 licensed.
